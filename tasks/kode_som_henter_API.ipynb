{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henter temperatur, trykk og nedbør...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leahs\\AppData\\Local\\Temp\\ipykernel_29468\\1160682549.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\"Dato\": dato, label: verdi}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagret til: ../data\\R_Temperatur (°C).csv\n",
      "Lagret til: ../data\\R_Lufttrykk (hPa).csv\n",
      "Lagret til: ../data\\R_Nedbør (mm).csv\n",
      "Henter data for relativ fuktighet (%)...\n",
      "Relativ fuktighet (%) lagret som: ../data\\R_Relativ fuktighet (%).csv\n",
      "Henter data for skydekke (oktas)...\n",
      "Skydekke (oktas) lagret som: ../data\\R_Skydekke (oktas).csv\n"
     ]
    }
   ],
   "source": [
    "#Oppdatert\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sett riktig mappe for lagring (opp ett nivå)\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "API = \"2a430097-ac9b-44e4-995e-a02afb9795b2\"\n",
    "SOURCE = \"SN18700\"\n",
    "BASE_URL = \"https://frost.met.no/observations/v0.jsonld\"\n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "delta = timedelta(days=30)\n",
    "\n",
    "# Elementer som hentes i batcher (i én spørring)\n",
    "elements_batch = {\n",
    "    \"mean(air_temperature P1D)\": \"Temperatur (°C)\",\n",
    "    \"mean(air_pressure_at_sea_level P1D)\": \"Lufttrykk (hPa)\",\n",
    "    \"sum(precipitation_amount P1D)\": \"Nedbør (mm)\"\n",
    "}\n",
    "\n",
    "# Elementer som må hentes separat (på grunn av API-begrensninger)\n",
    "elements_single = {\n",
    "    \"mean(relative_humidity P1D)\": \"Relativ fuktighet (%)\",\n",
    "    \"mean(cloud_area_fraction P1D)\": \"Skydekke (oktas)\"\n",
    "}\n",
    "\n",
    "force_update = input(\"Vil du hente nye data fra Frost API? (ja/nei): \").strip().lower()\n",
    "\n",
    "# Funksjon for å hente data i batcher\n",
    "def fetch_batch_elements():\n",
    "    dataframes = {label: pd.DataFrame(columns=[\"Dato\", label]) for label in elements_batch.values()}\n",
    "\n",
    "    if all(os.path.exists(os.path.join(data_dir, f\"{label}.csv\")) for label in elements_batch.values()) and force_update != \"ja\":\n",
    "        print(\"Bruker eksisterende filer for temperatur, trykk og nedbør.\")\n",
    "        return\n",
    "\n",
    "    print(\"Henter temperatur, trykk og nedbør...\")\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        batch_start = current_date.strftime(\"%Y-%m-%d\")\n",
    "        batch_end = min(current_date + delta, end_date).strftime(\"%Y-%m-%d\")\n",
    "        batch_reference_time = f\"{batch_start}/{batch_end}\"\n",
    "\n",
    "        params = {\n",
    "            \"sources\": SOURCE,\n",
    "            \"elements\": \",\".join(elements_batch.keys()),\n",
    "            \"referencetime\": batch_reference_time\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, params=params, auth=(API, \"\"))\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            raw_data = response.json().get(\"data\", [])\n",
    "            \n",
    "            for entry in raw_data:\n",
    "                dato = entry[\"referenceTime\"].split(\"T\")[0]\n",
    "                if dato > end_date.strftime(\"%Y-%m-%d\"):\n",
    "                    continue\n",
    "                for obs in entry[\"observations\"]:\n",
    "                    element_id = obs[\"elementId\"]\n",
    "                    verdi = obs[\"value\"]\n",
    "                    label = elements_batch[element_id]\n",
    "                    df = dataframes[label]\n",
    "\n",
    "                    df = pd.concat([df, pd.DataFrame([{\"Dato\": dato, label: verdi}])], ignore_index=True)\n",
    "                    dataframes[label] = df\n",
    "        else:\n",
    "            print(f\"Feil ved henting av data ({batch_reference_time}): {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "        current_date += delta\n",
    "\n",
    "    for label, df in dataframes.items():\n",
    "        df.drop_duplicates(subset=\"Dato\", keep=\"last\", inplace=True)\n",
    "        df.sort_values(\"Dato\", inplace=True)\n",
    "        df.to_csv(os.path.join(data_dir, f\"R_{label}.csv\"), index=False, encoding=\"utf-8\")\n",
    "        print(f\"Lagret til: {os.path.join(data_dir, f'R_{label}.csv')}\")\n",
    "\n",
    "# Funksjon for å hente enkeltstående elementer\n",
    "def fetch_single_element(element_id, label):\n",
    "    filename = os.path.join(data_dir, f\"R_{label}.csv\")\n",
    "    if os.path.exists(filename) and force_update != \"ja\":\n",
    "        print(f\"Bruker eksisterende fil: {filename}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Henter data for {label.lower()}...\")\n",
    "    params = {\n",
    "        \"sources\": SOURCE,\n",
    "        \"elements\": element_id,\n",
    "        \"referencetime\": f\"{start_date.strftime('%Y-%m-%d')}/{end_date.strftime('%Y-%m-%d')}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params, auth=(API, \"\"))\n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"data\", [])\n",
    "        rows = [(d[\"referenceTime\"].split(\"T\")[0], d[\"observations\"][0][\"value\"]) for d in data]\n",
    "        pd.DataFrame(rows, columns=[\"Dato\", label]).to_csv(filename, index=False, encoding=\"utf-8\")\n",
    "        print(f\"{label} lagret som: {filename}\")\n",
    "    else:\n",
    "        print(f\"Feil ved henting av {label.lower()}: {response.status_code}\\n{response.text}\")\n",
    "\n",
    "# Kjør begge deler\n",
    "fetch_batch_elements()\n",
    "for element_id, label in elements_single.items():\n",
    "    fetch_single_element(element_id, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kode som henter luftkvalitet fra API openwathermap:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henter data: 2023-01-01 - 2023-01-06\n",
      "Henter data: 2023-01-07 - 2023-01-12\n",
      "Henter data: 2023-01-13 - 2023-01-18\n",
      "Henter data: 2023-01-19 - 2023-01-24\n",
      "Henter data: 2023-01-25 - 2023-01-30\n",
      "Henter data: 2023-01-31 - 2023-02-05\n",
      "Henter data: 2023-02-06 - 2023-02-11\n",
      "Henter data: 2023-02-12 - 2023-02-17\n",
      "Henter data: 2023-02-18 - 2023-02-23\n",
      "Henter data: 2023-02-24 - 2023-03-01\n",
      "Henter data: 2023-03-02 - 2023-03-07\n",
      "Henter data: 2023-03-08 - 2023-03-13\n",
      "Henter data: 2023-03-14 - 2023-03-19\n",
      "Henter data: 2023-03-20 - 2023-03-25\n",
      "Henter data: 2023-03-26 - 2023-03-31\n",
      "Henter data: 2023-04-01 - 2023-04-06\n",
      "Henter data: 2023-04-07 - 2023-04-12\n",
      "Henter data: 2023-04-13 - 2023-04-18\n",
      "Henter data: 2023-04-19 - 2023-04-24\n",
      "Henter data: 2023-04-25 - 2023-04-30\n",
      "Henter data: 2023-05-01 - 2023-05-06\n",
      "Henter data: 2023-05-07 - 2023-05-12\n",
      "Henter data: 2023-05-13 - 2023-05-18\n",
      "Henter data: 2023-05-19 - 2023-05-24\n",
      "Henter data: 2023-05-25 - 2023-05-30\n",
      "Henter data: 2023-05-31 - 2023-06-05\n",
      "Henter data: 2023-06-06 - 2023-06-11\n",
      "Henter data: 2023-06-12 - 2023-06-17\n",
      "Henter data: 2023-06-18 - 2023-06-23\n",
      "Henter data: 2023-06-24 - 2023-06-29\n",
      "Henter data: 2023-06-30 - 2023-07-05\n",
      "Henter data: 2023-07-06 - 2023-07-11\n",
      "Henter data: 2023-07-12 - 2023-07-17\n",
      "Henter data: 2023-07-18 - 2023-07-23\n",
      "Henter data: 2023-07-24 - 2023-07-29\n",
      "Henter data: 2023-07-30 - 2023-08-04\n",
      "Henter data: 2023-08-05 - 2023-08-10\n",
      "Henter data: 2023-08-11 - 2023-08-16\n",
      "Henter data: 2023-08-17 - 2023-08-22\n",
      "Henter data: 2023-08-23 - 2023-08-28\n",
      "Henter data: 2023-08-29 - 2023-09-03\n",
      "Henter data: 2023-09-04 - 2023-09-09\n",
      "Henter data: 2023-09-10 - 2023-09-15\n",
      "Henter data: 2023-09-16 - 2023-09-21\n",
      "Henter data: 2023-09-22 - 2023-09-27\n",
      "Henter data: 2023-09-28 - 2023-10-03\n",
      "Henter data: 2023-10-04 - 2023-10-09\n",
      "Henter data: 2023-10-10 - 2023-10-15\n",
      "Henter data: 2023-10-16 - 2023-10-21\n",
      "Henter data: 2023-10-22 - 2023-10-27\n",
      "Henter data: 2023-10-28 - 2023-11-02\n",
      "Henter data: 2023-11-03 - 2023-11-08\n",
      "Henter data: 2023-11-09 - 2023-11-14\n",
      "Henter data: 2023-11-15 - 2023-11-20\n",
      "Henter data: 2023-11-21 - 2023-11-26\n",
      "Henter data: 2023-11-27 - 2023-12-02\n",
      "Henter data: 2023-12-03 - 2023-12-08\n",
      "Henter data: 2023-12-09 - 2023-12-14\n",
      "Henter data: 2023-12-15 - 2023-12-20\n",
      "Henter data: 2023-12-21 - 2023-12-26\n",
      "Henter data: 2023-12-27 - 2024-01-01\n",
      "Henter data: 2024-01-02 - 2024-01-07\n",
      "Henter data: 2024-01-08 - 2024-01-13\n",
      "Henter data: 2024-01-14 - 2024-01-19\n",
      "Henter data: 2024-01-20 - 2024-01-25\n",
      "Henter data: 2024-01-26 - 2024-01-31\n",
      "Henter data: 2024-02-01 - 2024-02-06\n",
      "Henter data: 2024-02-07 - 2024-02-12\n",
      "Henter data: 2024-02-13 - 2024-02-18\n",
      "Henter data: 2024-02-19 - 2024-02-24\n",
      "Henter data: 2024-02-25 - 2024-03-01\n",
      "Henter data: 2024-03-02 - 2024-03-07\n",
      "Henter data: 2024-03-08 - 2024-03-13\n",
      "Henter data: 2024-03-14 - 2024-03-19\n",
      "Henter data: 2024-03-20 - 2024-03-25\n",
      "Henter data: 2024-03-26 - 2024-03-31\n",
      "Henter data: 2024-04-01 - 2024-04-06\n",
      "Henter data: 2024-04-07 - 2024-04-12\n",
      "Henter data: 2024-04-13 - 2024-04-18\n",
      "Henter data: 2024-04-19 - 2024-04-24\n",
      "Henter data: 2024-04-25 - 2024-04-30\n",
      "Henter data: 2024-05-01 - 2024-05-06\n",
      "Henter data: 2024-05-07 - 2024-05-12\n",
      "Henter data: 2024-05-13 - 2024-05-18\n",
      "Henter data: 2024-05-19 - 2024-05-24\n",
      "Henter data: 2024-05-25 - 2024-05-30\n",
      "Henter data: 2024-05-31 - 2024-06-05\n",
      "Henter data: 2024-06-06 - 2024-06-11\n",
      "Henter data: 2024-06-12 - 2024-06-17\n",
      "Henter data: 2024-06-18 - 2024-06-23\n",
      "Henter data: 2024-06-24 - 2024-06-29\n",
      "Henter data: 2024-06-30 - 2024-07-05\n",
      "Henter data: 2024-07-06 - 2024-07-11\n",
      "Henter data: 2024-07-12 - 2024-07-17\n",
      "Henter data: 2024-07-18 - 2024-07-23\n",
      "Henter data: 2024-07-24 - 2024-07-29\n",
      "Henter data: 2024-07-30 - 2024-08-04\n",
      "Henter data: 2024-08-05 - 2024-08-10\n",
      "Henter data: 2024-08-11 - 2024-08-16\n",
      "Henter data: 2024-08-17 - 2024-08-22\n",
      "Henter data: 2024-08-23 - 2024-08-28\n",
      "Henter data: 2024-08-29 - 2024-09-03\n",
      "Henter data: 2024-09-04 - 2024-09-09\n",
      "Henter data: 2024-09-10 - 2024-09-15\n",
      "Henter data: 2024-09-16 - 2024-09-21\n",
      "Henter data: 2024-09-22 - 2024-09-27\n",
      "Henter data: 2024-09-28 - 2024-10-03\n",
      "Henter data: 2024-10-04 - 2024-10-09\n",
      "Henter data: 2024-10-10 - 2024-10-15\n",
      "Henter data: 2024-10-16 - 2024-10-21\n",
      "Henter data: 2024-10-22 - 2024-10-27\n",
      "Henter data: 2024-10-28 - 2024-11-02\n",
      "Henter data: 2024-11-03 - 2024-11-08\n",
      "Henter data: 2024-11-09 - 2024-11-14\n",
      "Henter data: 2024-11-15 - 2024-11-20\n",
      "Henter data: 2024-11-21 - 2024-11-26\n",
      "Henter data: 2024-11-27 - 2024-12-02\n",
      "Henter data: 2024-12-03 - 2024-12-08\n",
      "Henter data: 2024-12-09 - 2024-12-14\n",
      "Henter data: 2024-12-15 - 2024-12-20\n",
      "Henter data: 2024-12-21 - 2024-12-26\n",
      "Henter data: 2024-12-27 - 2024-12-31\n",
      "\n",
      " Ferdig! CSV med daglig snitt lagret som: ../data\\R_luftkvalitet.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# --- Innstillinger ---\n",
    "API_KEY = \"e9ad2e06b3f1d6b100c9b20186bf202d\" \n",
    "# Kordinater til Trondheim Torg\n",
    "LAT = 63.4305 \n",
    "LON = 10.3951\n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "\n",
    "def to_unix(dt):\n",
    "    return int(time.mktime(dt.timetuple()))\n",
    "\n",
    "# --- Hent data ---\n",
    "results = []\n",
    "\n",
    "current_start = start_date\n",
    "while current_start <= end_date:\n",
    "    current_end = min(current_start + timedelta(days=5), end_date)\n",
    "    url = (\n",
    "        f\"http://api.openweathermap.org/data/2.5/air_pollution/history\"\n",
    "        f\"?lat={LAT}&lon={LON}\"\n",
    "        f\"&start={to_unix(current_start)}&end={to_unix(current_end)}\"\n",
    "        f\"&appid={API_KEY}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Henter data: {current_start.date()} - {current_end.date()}\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"list\", [])\n",
    "        results.extend(data)\n",
    "    else:\n",
    "        print(f\" Feil: {response.status_code} for {current_start.date()}\")\n",
    "\n",
    "    current_start = current_end + timedelta(days=1)\n",
    "    time.sleep(1)\n",
    "\n",
    "# --- Grupper og beregn snitt per dag ---\n",
    "daily_data = defaultdict(lambda: {\"pm2_5\": [], \"pm10\": [], \"no2\": [], \"o3\": []})\n",
    "\n",
    "for entry in results:\n",
    "    dt = datetime.utcfromtimestamp(entry[\"dt\"])\n",
    "    if dt.date() < datetime(2023, 1, 1).date():\n",
    "        continue  # Hopp over alt før 2023-01-01\n",
    "    date_key = dt.date().isoformat()        \n",
    "    components = entry[\"components\"]\n",
    "    for comp in [\"pm2_5\", \"pm10\", \"no2\", \"o3\"]:\n",
    "        if comp in components:\n",
    "            daily_data[date_key][comp].append(components[comp])\n",
    "\n",
    "\n",
    "            \n",
    "# --- Regn ut gjennomsnitt ---\n",
    "aggregated_rows = []\n",
    "for date, values in sorted(daily_data.items()):\n",
    "    row = {\"date\": date}\n",
    "    for comp, measurements in values.items():\n",
    "        if measurements:\n",
    "            row[comp] = round(sum(measurements) / len(measurements), 2)\n",
    "        else:\n",
    "            row[comp] = None\n",
    "    aggregated_rows.append(row)\n",
    "\n",
    "# --- Skriv til CSV ---\n",
    "csv_file = os.path.join(data_dir, \"R_luftkvalitet.csv\")\n",
    "fieldnames = [\"date\", \"pm2_5\", \"pm10\", \"no2\", \"o3\"]\n",
    "\n",
    "with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(aggregated_rows)\n",
    "\n",
    "print(f\"\\n Ferdig! CSV med daglig snitt lagret som: {csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
